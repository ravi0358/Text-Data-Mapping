{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb3a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import logging\n",
    "#import pyLDAvis.gensim\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "import gensim\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from numpy import array\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13b047cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from packages import *\n",
    "incident_ci_data,incident_data=create_incident_data()\n",
    "# problems_ci_data,problems_data=create_problem_data()\n",
    "# change_ci_data,change_data=create_change_data()\n",
    "# incident_ci_problem_mapped_df,incident_problem_mapped_df=create_incident_problem_data()\n",
    "sr_ci_data=create_sr_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96582d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(incident_ci_data[incident_ci_data['Incident CI Name']=='IMDM-Equity-MDM']['Incident Short Description'],columns=['Incident Short Description']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4bdc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dae87af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4047"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['Incident Short Description'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d516c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Incident Short Description'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3fb49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    new_text=''.join([char for char in text if char not in string.punctuation])\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59f957d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#punctuation removing\n",
    "df['Incident Short Description']=df['Incident Short Description'].apply(lambda row : remove_punctuation(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92a9d072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident Short Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DBI Dropped IDs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Europe Corporate Action  IPO Effective 01st Ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>US Corporate Action  IPO Effective 1st Jan 2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Financial Calendar  New Holiday Centres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>OTHERTracerReplications alert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Incident Short Description\n",
       "19                                    DBI Dropped IDs\n",
       "30  Europe Corporate Action  IPO Effective 01st Ja...\n",
       "62    US Corporate Action  IPO Effective 1st Jan 2020\n",
       "64            Financial Calendar  New Holiday Centres\n",
       "75                     OTHERTracerReplications alert "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ef26c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Incident Short Description']  = df['Incident Short Description'] .map(lambda x: x.lower())\n",
    "#Remove digits\n",
    "df['Incident Short Description'] = df['Incident Short Description'].str.replace('\\d+', '')\n",
    "#Remove one and two letter words\n",
    "df['Incident Short Description'] = df['Incident Short Description'].str.replace(r'\\b(\\w{1,2})\\b', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40188d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident Short Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dbi dropped ids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>europe corporate action  ipo effective  jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>corporate action  ipo effective  jan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>financial calendar  new holiday centres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>othertracerreplications alert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Incident Short Description\n",
       "19                              dbi dropped ids\n",
       "30  europe corporate action  ipo effective  jan\n",
       "62        corporate action  ipo effective  jan \n",
       "64      financial calendar  new holiday centres\n",
       "75               othertracerreplications alert "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f2f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb5732a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['dbi', 'dropped', 'ids'], ['europe', 'corporate', 'action', 'ipo', 'effective', 'jan'], ['corporate', 'action', 'ipo', 'effective', 'jan'], ['financial', 'calendar', 'new', 'holiday', 'centres'], ['alert']]\n"
     ]
    }
   ],
   "source": [
    "#tokenize each sentence into a list of words, removing punctuations and unnecessary characters altogether.\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data = df['Incident Short Description'].values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "436b839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['final_text'] = df.final_text.str.replace(r'\\b(\\w{1,2})\\b', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f59040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a69883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3191d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81ce6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "#!pip install spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af51f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ef2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af91e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering 1-30 topics, as the last is cut off\n",
    "num_topics = list(range(30)[1:])\n",
    "num_keywords = 15\n",
    "\n",
    "LDA_models = {}\n",
    "LDA_topics = {}\n",
    "for i in num_topics:\n",
    "    LDA_models[i] = LdaModel(corpus=corpus,\n",
    "                             id2word=id2word,\n",
    "                             num_topics=i,\n",
    "                             update_every=1,\n",
    "                             chunksize=len(corpus),\n",
    "                             passes=20,\n",
    "                             alpha='auto',\n",
    "                             random_state=42)\n",
    "\n",
    "    shown_topics = LDA_models[i].show_topics(num_topics=i, \n",
    "                                             num_words=num_keywords,\n",
    "                                             formatted=False)\n",
    "    LDA_topics[i] = [[word[0] for word in topic[1]] for topic in shown_topics]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292cefad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(topic_1, topic_2):\n",
    "    \"\"\"\n",
    "    Derives the Jaccard similarity of two topics\n",
    "\n",
    "    Jaccard similarity:\n",
    "    - A statistic used for comparing the similarity and diversity of sample sets\n",
    "    - J(A,B) = (A ∩ B)/(A ∪ B)\n",
    "    - Goal is low Jaccard scores for coverage of the diverse elements\n",
    "    \"\"\"\n",
    "    intersection = set(topic_1).intersection(set(topic_2))\n",
    "    union = set(topic_1).union(set(topic_2))\n",
    "                    \n",
    "    return float(len(intersection))/float(len(union))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2002d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_stability = {}\n",
    "for i in range(0, len(num_topics)-1):\n",
    "    jaccard_sims = []\n",
    "    for t1, topic1 in enumerate(LDA_topics[num_topics[i]]): # pylint: disable=unused-variable\n",
    "        sims = []\n",
    "        for t2, topic2 in enumerate(LDA_topics[num_topics[i+1]]): # pylint: disable=unused-variable\n",
    "            sims.append(jaccard_similarity(topic1, topic2))    \n",
    "        \n",
    "        jaccard_sims.append(sims)    \n",
    "    \n",
    "    LDA_stability[num_topics[i]] = jaccard_sims\n",
    "                \n",
    "mean_stabilities = [np.array(LDA_stability[i]).mean() for i in num_topics[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27394794",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherences = [CoherenceModel(model=LDA_models[i], texts=data_lemmatized, dictionary=id2word, coherence='c_v').get_coherence()\\\n",
    "              for i in num_topics[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ed5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coh_sta_diffs = [coherences[i] - mean_stabilities[i] for i in range(num_keywords)[:-1]] # limit topic numbers to the number of keywords\n",
    "coh_sta_max = max(coh_sta_diffs)\n",
    "coh_sta_max_idxs = [i for i, j in enumerate(coh_sta_diffs) if j == coh_sta_max]\n",
    "ideal_topic_num_index = coh_sta_max_idxs[0] # choose less topics in case there's more than one max\n",
    "ideal_topic_num = num_topics[ideal_topic_num_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c14c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "ax = sns.lineplot(x=num_topics[:-1], y=mean_stabilities, label='Average Topic Overlap')\n",
    "ax = sns.lineplot(x=num_topics[:-1], y=coherences, label='Topic Coherence')\n",
    "\n",
    "ax.axvline(x=ideal_topic_num, label='Ideal Number of Topics', color='black')\n",
    "ax.axvspan(xmin=ideal_topic_num - 1, xmax=ideal_topic_num + 1, alpha=0.5, facecolor='grey')\n",
    "\n",
    "y_max = max(max(mean_stabilities), max(coherences)) + (0.10 * max(max(mean_stabilities), max(coherences)))\n",
    "ax.set_ylim([0, y_max])\n",
    "ax.set_xlim([1, num_topics[-1]-1])\n",
    "                \n",
    "ax.axes.set_title('Model Metrics per Number of Topics', fontsize=25)\n",
    "ax.set_ylabel('Metric Level', fontsize=20)\n",
    "ax.set_xlabel('Number of Topics', fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c424e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your ideal number of topics will maximize coherence and minimize the topic overlap based on Jaccard similarity. \n",
    "#In this case it looks like we'd be safe choosing topic numbers around ideal_topic_num.\n",
    "\n",
    "ideal_topic_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_topics = ideal_topic_num\n",
    "\n",
    "\n",
    "\n",
    "LDA_models_final = LdaModel(corpus=corpus,\n",
    "                             id2word=id2word,\n",
    "                             num_topics=ideal_topic_num,\n",
    "                             update_every=1,\n",
    "                             chunksize=len(corpus),\n",
    "                             passes=20,\n",
    "                             alpha='auto',\n",
    "                             random_state=42)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843d537",
   "metadata": {},
   "outputs": [],
   "source": [
    "shown_topics_final = LDA_models_final.show_topics(num_topics=ideal_topic_num,num_words=15,formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958abb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_topics_final = [[word[0] for word in topic[1]] for topic in shown_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0c4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['main_topic'] = [int(str(sorted(LDA_models_final[i],reverse=True,key=lambda x: x[1])[0][0]).zfill(3)) for i in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2619096",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn =[]\n",
    "tnames=[]\n",
    "for i in range(len(shown_topics_final)):\n",
    "    tn.append(shown_topics_final[i][0])\n",
    "    tnames.append(shown_topics_final[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tnames = pd.DataFrame(list(zip(tn, tnames)),columns=['topic_num','topic_names'])\n",
    "df_tnames['topic_names'] = df_tnames['topic_names'].astype('str')\n",
    "df_tnames['topic_names']=df_tnames['topic_names'].apply(lambda row: remove_punctuation(row))\n",
    "df_tnames['topic_names']=df_tnames['topic_names'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a306e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df.merge(df_tnames,left_on='main_topic',right_on='topic_num',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f71a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.drop('main_topic',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e912d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('IMDM_Topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4281ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['Incident Short Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6322819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m68",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m68"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
